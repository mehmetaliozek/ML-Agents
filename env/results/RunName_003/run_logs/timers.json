{
    "name": "root",
    "gauges": {
        "PathfinderAgent.Policy.Entropy.mean": {
            "value": 1.667028784751892,
            "min": 1.420034646987915,
            "max": 1.6892138719558716,
            "count": 70
        },
        "PathfinderAgent.Policy.Entropy.sum": {
            "value": 83138.0625,
            "min": 71105.515625,
            "max": 84713.21875,
            "count": 70
        },
        "PathfinderAgent.Environment.EpisodeLength.mean": {
            "value": 43.26974267968057,
            "min": 43.26974267968057,
            "max": 1874.0,
            "count": 70
        },
        "PathfinderAgent.Environment.EpisodeLength.sum": {
            "value": 48765.0,
            "min": 39120.0,
            "max": 55433.0,
            "count": 70
        },
        "PathfinderAgent.Step.mean": {
            "value": 3499999.0,
            "min": 49984.0,
            "max": 3499999.0,
            "count": 70
        },
        "PathfinderAgent.Step.sum": {
            "value": 3499999.0,
            "min": 49984.0,
            "max": 3499999.0,
            "count": 70
        },
        "PathfinderAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.1275558471679688,
            "min": -0.04616139084100723,
            "max": 1.1429791450500488,
            "count": 70
        },
        "PathfinderAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 1507.5421142578125,
            "min": -38.36011505126953,
            "max": 1542.447509765625,
            "count": 70
        },
        "PathfinderAgent.Environment.CumulativeReward.mean": {
            "value": 1.4829172711925187,
            "min": -0.9032932921492309,
            "max": 1.495552317743438,
            "count": 70
        },
        "PathfinderAgent.Environment.CumulativeReward.sum": {
            "value": 1671.2477646339685,
            "min": -101.16884872071387,
            "max": 1671.2477646339685,
            "count": 70
        },
        "PathfinderAgent.Policy.ExtrinsicReward.mean": {
            "value": 1.4829172711925187,
            "min": -0.9032932921492309,
            "max": 1.495552317743438,
            "count": 70
        },
        "PathfinderAgent.Policy.ExtrinsicReward.sum": {
            "value": 1671.2477646339685,
            "min": -101.16884872071387,
            "max": 1671.2477646339685,
            "count": 70
        },
        "PathfinderAgent.Losses.PolicyLoss.mean": {
            "value": 0.1374106210253861,
            "min": 0.06875072184993769,
            "max": 0.1407538345414044,
            "count": 70
        },
        "PathfinderAgent.Losses.PolicyLoss.sum": {
            "value": 0.2748212420507722,
            "min": 0.06875072184993769,
            "max": 0.2815076690828088,
            "count": 70
        },
        "PathfinderAgent.Losses.ValueLoss.mean": {
            "value": 0.011021981785840278,
            "min": 0.001045837356021669,
            "max": 0.04592080359968046,
            "count": 70
        },
        "PathfinderAgent.Losses.ValueLoss.sum": {
            "value": 0.022043963571680557,
            "min": 0.001341903973980152,
            "max": 0.05840706778690219,
            "count": 70
        },
        "PathfinderAgent.Policy.LearningRate.mean": {
            "value": 6.116662941672e-05,
            "min": 6.116662941672e-05,
            "max": 0.00019873520063239995,
            "count": 70
        },
        "PathfinderAgent.Policy.LearningRate.sum": {
            "value": 0.00012233325883344,
            "min": 0.00010099596950203999,
            "max": 0.00039361504319247997,
            "count": 70
        },
        "PathfinderAgent.Policy.Epsilon.mean": {
            "value": 0.13058328,
            "min": 0.13058328,
            "max": 0.1993676,
            "count": 70
        },
        "PathfinderAgent.Policy.Epsilon.sum": {
            "value": 0.26116656,
            "min": 0.15049796000000001,
            "max": 0.39680752,
            "count": 70
        },
        "PathfinderAgent.Policy.Beta.mean": {
            "value": 0.009181925672,
            "min": 0.009181925672,
            "max": 0.029810343239999995,
            "count": 70
        },
        "PathfinderAgent.Policy.Beta.sum": {
            "value": 0.018363851344,
            "min": 0.015154338203999999,
            "max": 0.059042575247999995,
            "count": 70
        },
        "PathfinderAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 70
        },
        "PathfinderAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 70
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1756203451",
        "python_version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\MehmetAli\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\mlagents-learn conf.yaml --run-id=RunName_003",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.5.1+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1756212223"
    },
    "total": 8771.477297899999,
    "count": 1,
    "self": 0.017647299999225652,
    "children": {
        "run_training.setup": {
            "total": 0.14644110000017463,
            "count": 1,
            "self": 0.14644110000017463
        },
        "TrainerController.start_learning": {
            "total": 8771.3132095,
            "count": 1,
            "self": 6.002484899498086,
            "children": {
                "TrainerController._reset_env": {
                    "total": 13.424426099999891,
                    "count": 1,
                    "self": 13.424426099999891
                },
                "TrainerController.advance": {
                    "total": 8751.694947100503,
                    "count": 243332,
                    "self": 5.438551600325809,
                    "children": {
                        "env_step": {
                            "total": 7172.841476299755,
                            "count": 243332,
                            "self": 6065.242778999672,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1103.7019000000428,
                                    "count": 243332,
                                    "self": 24.606593500103827,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1079.095306499939,
                                            "count": 219707,
                                            "self": 1079.095306499939
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 3.8967973000408165,
                                    "count": 243331,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 8754.963272999961,
                                            "count": 243331,
                                            "is_parallel": true,
                                            "self": 3092.2082101002416,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.028188499999941996,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00013320000016392441,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.02805529999977807,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.02805529999977807
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 5662.726874399719,
                                                    "count": 243331,
                                                    "is_parallel": true,
                                                    "self": 28.51710049904341,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 158.1323266002114,
                                                            "count": 243331,
                                                            "is_parallel": true,
                                                            "self": 158.1323266002114
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 5306.7642499004705,
                                                            "count": 243331,
                                                            "is_parallel": true,
                                                            "self": 5306.7642499004705
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 169.31319739999435,
                                                            "count": 243331,
                                                            "is_parallel": true,
                                                            "self": 24.168985000062094,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 145.14421239993226,
                                                                    "count": 973324,
                                                                    "is_parallel": true,
                                                                    "self": 145.14421239993226
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1573.4149192004215,
                            "count": 243331,
                            "self": 8.394631500248124,
                            "children": {
                                "process_trajectory": {
                                    "total": 1233.2350934001697,
                                    "count": 243331,
                                    "self": 1231.5498301001671,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 1.685263300002589,
                                            "count": 7,
                                            "self": 1.685263300002589
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 331.7851943000037,
                                    "count": 121,
                                    "self": 49.35672800003704,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 282.42846629996666,
                                            "count": 11616,
                                            "self": 282.42846629996666
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.999995770864189e-07,
                    "count": 1,
                    "self": 8.999995770864189e-07
                },
                "TrainerController._save_models": {
                    "total": 0.19135049999931653,
                    "count": 1,
                    "self": 0.017164700000648736,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.1741857999986678,
                            "count": 1,
                            "self": 0.1741857999986678
                        }
                    }
                }
            }
        }
    }
}